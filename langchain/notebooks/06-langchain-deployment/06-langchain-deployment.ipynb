{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 06 - LangChain éƒ¨ç½²å¯¦å‹™\n",
    "\n",
    "## ğŸ“š å­¸ç¿’ç›®æ¨™\n",
    "\n",
    "- âœ… ç†è§£ LangChain æ‡‰ç”¨çš„éƒ¨ç½²æ¶æ§‹\n",
    "- âœ… ä½¿ç”¨ FastAPI å»ºç«‹ REST API\n",
    "- âœ… å¯¦ä½œä¸²æµå›æ‡‰ (Streaming)\n",
    "- âœ… Docker å®¹å™¨åŒ–éƒ¨ç½²\n",
    "- âœ… ç”Ÿç”¢ç’°å¢ƒæœ€ä½³å¯¦è¸\n",
    "\n",
    "## â° é è¨ˆæ™‚é–“: 50 åˆ†é˜"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“¦ ç’°å¢ƒè¨­å®š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install langchain==0.1.0\n",
    "!pip install langchain-openai==0.0.5\n",
    "!pip install fastapi==0.108.0\n",
    "!pip install uvicorn==0.25.0\n",
    "!pip install pydantic==2.5.0\n",
    "!pip install python-dotenv==1.0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "print(\"âœ… ç’°å¢ƒè¨­å®šå®Œæˆ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: éƒ¨ç½²æ¶æ§‹æ¦‚è¦½\n",
    "\n",
    "### 1.1 å…¸å‹çš„ LangChain æ‡‰ç”¨æ¶æ§‹\n",
    "\n",
    "```\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚         LangChain æ‡‰ç”¨éƒ¨ç½²æ¶æ§‹               â”‚\n",
    "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
    "â”‚                                             â”‚\n",
    "â”‚  å‰ç«¯ (Web/Mobile)                          â”‚\n",
    "â”‚         â†“ HTTP/WebSocket                    â”‚\n",
    "â”‚  API Gateway (FastAPI)                      â”‚\n",
    "â”‚         â†“                                   â”‚\n",
    "â”‚  Business Logic Layer                       â”‚\n",
    "â”‚    â”œâ”€â”€ LangChain Agents                     â”‚\n",
    "â”‚    â”œâ”€â”€ Memory Management                    â”‚\n",
    "â”‚    â””â”€â”€ Tool Integration                     â”‚\n",
    "â”‚         â†“                                   â”‚\n",
    "â”‚  External Services                          â”‚\n",
    "â”‚    â”œâ”€â”€ OpenAI API                           â”‚\n",
    "â”‚    â”œâ”€â”€ Database                             â”‚\n",
    "â”‚    â””â”€â”€ Cache (Redis)                        â”‚\n",
    "â”‚                                             â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: FastAPI REST API\n",
    "\n",
    "### 2.1 åŸºç¤ FastAPI æ‡‰ç”¨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastapi import FastAPI, HTTPException\n",
    "from pydantic import BaseModel\n",
    "from typing import List, Optional\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "# å»ºç«‹ FastAPI æ‡‰ç”¨\n",
    "app = FastAPI(\n",
    "    title=\"åœ‹æ³°äººå£½ AI å®¢æœ API\",\n",
    "    description=\"LangChain é©…å‹•çš„æ™ºèƒ½å®¢æœç³»çµ±\",\n",
    "    version=\"1.0.0\"\n",
    ")\n",
    "\n",
    "# åˆå§‹åŒ– LLM\n",
    "llm = ChatOpenAI(model=\"gpt-4\", temperature=0.7)\n",
    "\n",
    "# å®šç¾©è«‹æ±‚/å›æ‡‰æ¨¡å‹\n",
    "class QueryRequest(BaseModel):\n",
    "    \"\"\"æŸ¥è©¢è«‹æ±‚\"\"\"\n",
    "    user_id: str\n",
    "    message: str\n",
    "    session_id: Optional[str] = None\n",
    "\n",
    "class QueryResponse(BaseModel):\n",
    "    \"\"\"æŸ¥è©¢å›æ‡‰\"\"\"\n",
    "    response: str\n",
    "    session_id: str\n",
    "\n",
    "@app.get(\"/\")\n",
    "async def root():\n",
    "    \"\"\"å¥åº·æª¢æŸ¥ç«¯é»\"\"\"\n",
    "    return {\n",
    "        \"status\": \"healthy\",\n",
    "        \"service\": \"Cathay AI Customer Service\",\n",
    "        \"version\": \"1.0.0\"\n",
    "    }\n",
    "\n",
    "@app.post(\"/chat\", response_model=QueryResponse)\n",
    "async def chat(request: QueryRequest):\n",
    "    \"\"\"èŠå¤©ç«¯é»\"\"\"\n",
    "    try:\n",
    "        # å»ºç«‹æç¤ºè©\n",
    "        prompt = ChatPromptTemplate.from_messages([\n",
    "            (\"system\", \"ä½ æ˜¯åœ‹æ³°äººå£½çš„å°ˆæ¥­å®¢æœåŠ©ç†,è«‹ç”¨å‹å–„ä¸”å°ˆæ¥­çš„æ…‹åº¦å›ç­”å•é¡Œã€‚\"),\n",
    "            (\"user\", \"{message}\")\n",
    "        ])\n",
    "        \n",
    "        # åŸ·è¡Œ\n",
    "        chain = prompt | llm\n",
    "        response = chain.invoke({\"message\": request.message})\n",
    "        \n",
    "        return QueryResponse(\n",
    "            response=response.content,\n",
    "            session_id=request.session_id or \"new-session\"\n",
    "        )\n",
    "        \n",
    "    except Exception as e:\n",
    "        raise HTTPException(status_code=500, detail=str(e))\n",
    "\n",
    "print(\"âœ… FastAPI æ‡‰ç”¨å»ºç«‹å®Œæˆ\")\n",
    "print(\"\\nğŸ’¡ å•Ÿå‹•æ–¹å¼:\")\n",
    "print(\"uvicorn main:app --reload\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 ä¿å–®æŸ¥è©¢ API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from enum import Enum\n",
    "\n",
    "class PolicyType(str, Enum):\n",
    "    LIFE = \"çµ‚èº«å£½éšª\"\n",
    "    TERM = \"å®šæœŸå£½éšª\"\n",
    "    MEDICAL = \"é†«ç™‚éšª\"\n",
    "    ACCIDENT = \"æ„å¤–éšª\"\n",
    "\n",
    "class PolicyInfo(BaseModel):\n",
    "    \"\"\"ä¿å–®è³‡è¨Š\"\"\"\n",
    "    policy_id: str\n",
    "    policy_type: PolicyType\n",
    "    owner_name: str\n",
    "    coverage: int\n",
    "    annual_premium: int\n",
    "    status: str\n",
    "\n",
    "# æ¨¡æ“¬è³‡æ–™åº«\n",
    "MOCK_DB = {\n",
    "    \"CL202401001\": PolicyInfo(\n",
    "        policy_id=\"CL202401001\",\n",
    "        policy_type=PolicyType.LIFE,\n",
    "        owner_name=\"ç‹å°æ˜\",\n",
    "        coverage=2000000,\n",
    "        annual_premium=50000,\n",
    "        status=\"æœ‰æ•ˆ\"\n",
    "    ),\n",
    "    \"CL202401002\": PolicyInfo(\n",
    "        policy_id=\"CL202401002\",\n",
    "        policy_type=PolicyType.MEDICAL,\n",
    "        owner_name=\"æå°è¯\",\n",
    "        coverage=1000000,\n",
    "        annual_premium=30000,\n",
    "        status=\"æœ‰æ•ˆ\"\n",
    "    )\n",
    "}\n",
    "\n",
    "@app.get(\"/policy/{policy_id}\", response_model=PolicyInfo)\n",
    "async def get_policy(policy_id: str):\n",
    "    \"\"\"æŸ¥è©¢ä¿å–®è³‡è¨Š\"\"\"\n",
    "    if policy_id not in MOCK_DB:\n",
    "        raise HTTPException(status_code=404, detail=f\"æ‰¾ä¸åˆ°ä¿å–® {policy_id}\")\n",
    "    \n",
    "    return MOCK_DB[policy_id]\n",
    "\n",
    "@app.get(\"/policies\", response_model=List[PolicyInfo])\n",
    "async def list_policies(owner_name: Optional[str] = None):\n",
    "    \"\"\"åˆ—å‡ºä¿å–®\"\"\"\n",
    "    policies = list(MOCK_DB.values())\n",
    "    \n",
    "    if owner_name:\n",
    "        policies = [p for p in policies if p.owner_name == owner_name]\n",
    "    \n",
    "    return policies\n",
    "\n",
    "print(\"âœ… ä¿å–® API ç«¯é»å»ºç«‹å®Œæˆ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 AI è«®è©¢ API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.tools import tool\n",
    "from langchain.agents import create_react_agent, AgentExecutor\n",
    "from langchain import hub\n",
    "\n",
    "# å®šç¾©å·¥å…·\n",
    "@tool\n",
    "def search_policy_tool(policy_id: str) -> str:\n",
    "    \"\"\"æŸ¥è©¢ä¿å–®è³‡è¨Š\"\"\"\n",
    "    if policy_id in MOCK_DB:\n",
    "        p = MOCK_DB[policy_id]\n",
    "        return f\"ä¿å–® {p.policy_id}: {p.policy_type.value}, æŠ•ä¿äºº {p.owner_name}, ä¿é¡ ${p.coverage:,}, å¹´ç¹³ ${p.annual_premium:,}, ç‹€æ…‹ {p.status}\"\n",
    "    return f\"æ‰¾ä¸åˆ°ä¿å–® {policy_id}\"\n",
    "\n",
    "@tool\n",
    "def calculate_premium_tool(age: int, coverage: int) -> str:\n",
    "    \"\"\"è¨ˆç®—ä¿è²»\"\"\"\n",
    "    base_rate = 0.02\n",
    "    age_factor = 1 + (age - 30) * 0.01\n",
    "    premium = int(coverage * base_rate * age_factor)\n",
    "    return f\"å¹´é½¡ {age} æ­²,ä¿é¡ ${coverage:,},å¹´ç¹³ä¿è²»ç´„ ${premium:,}\"\n",
    "\n",
    "# å»ºç«‹ Agent\n",
    "tools = [search_policy_tool, calculate_premium_tool]\n",
    "prompt = hub.pull(\"hwchase17/react\")\n",
    "agent = create_react_agent(llm, tools, prompt)\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)\n",
    "\n",
    "class AgentRequest(BaseModel):\n",
    "    \"\"\"Agent è«‹æ±‚\"\"\"\n",
    "    query: str\n",
    "\n",
    "class AgentResponse(BaseModel):\n",
    "    \"\"\"Agent å›æ‡‰\"\"\"\n",
    "    answer: str\n",
    "\n",
    "@app.post(\"/agent/query\", response_model=AgentResponse)\n",
    "async def agent_query(request: AgentRequest):\n",
    "    \"\"\"AI Agent æŸ¥è©¢\"\"\"\n",
    "    try:\n",
    "        result = agent_executor.invoke({\"input\": request.query})\n",
    "        return AgentResponse(answer=result[\"output\"])\n",
    "    except Exception as e:\n",
    "        raise HTTPException(status_code=500, detail=str(e))\n",
    "\n",
    "print(\"âœ… AI Agent API å»ºç«‹å®Œæˆ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: ä¸²æµå›æ‡‰ (Streaming)\n",
    "\n",
    "### 3.1 å¯¦ä½œ Server-Sent Events (SSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastapi.responses import StreamingResponse\n",
    "import asyncio\n",
    "\n",
    "@app.post(\"/chat/stream\")\n",
    "async def chat_stream(request: QueryRequest):\n",
    "    \"\"\"ä¸²æµèŠå¤©å›æ‡‰\"\"\"\n",
    "    \n",
    "    async def generate():\n",
    "        \"\"\"ç”Ÿæˆä¸²æµå›æ‡‰\"\"\"\n",
    "        prompt = ChatPromptTemplate.from_messages([\n",
    "            (\"system\", \"ä½ æ˜¯åœ‹æ³°äººå£½çš„å®¢æœåŠ©ç†\"),\n",
    "            (\"user\", \"{message}\")\n",
    "        ])\n",
    "        \n",
    "        chain = prompt | llm\n",
    "        \n",
    "        # ä½¿ç”¨ stream æ–¹æ³•\n",
    "        async for chunk in chain.astream({\"message\": request.message}):\n",
    "            if chunk.content:\n",
    "                # SSE æ ¼å¼\n",
    "                yield f\"data: {chunk.content}\\n\\n\"\n",
    "                await asyncio.sleep(0.05)  # æ¨¡æ“¬æ‰“å­—æ•ˆæœ\n",
    "        \n",
    "        yield \"data: [DONE]\\n\\n\"\n",
    "    \n",
    "    return StreamingResponse(\n",
    "        generate(),\n",
    "        media_type=\"text/event-stream\",\n",
    "        headers={\n",
    "            \"Cache-Control\": \"no-cache\",\n",
    "            \"Connection\": \"keep-alive\",\n",
    "        }\n",
    "    )\n",
    "\n",
    "print(\"âœ… ä¸²æµ API å»ºç«‹å®Œæˆ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: Docker å®¹å™¨åŒ–\n",
    "\n",
    "### 4.1 Dockerfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dockerfile_content = '''\n",
    "# ä½¿ç”¨å®˜æ–¹ Python æ˜ åƒ\n",
    "FROM python:3.11-slim\n",
    "\n",
    "# è¨­å®šå·¥ä½œç›®éŒ„\n",
    "WORKDIR /app\n",
    "\n",
    "# å®‰è£ç³»çµ±ä¾è³´\n",
    "RUN apt-get update && apt-get install -y \\\\\n",
    "    build-essential \\\\\n",
    "    && rm -rf /var/lib/apt/lists/*\n",
    "\n",
    "# è¤‡è£½ requirements\n",
    "COPY requirements.txt .\n",
    "\n",
    "# å®‰è£ Python ä¾è³´\n",
    "RUN pip install --no-cache-dir -r requirements.txt\n",
    "\n",
    "# è¤‡è£½æ‡‰ç”¨ç¨‹å¼ç¢¼\n",
    "COPY . .\n",
    "\n",
    "# æš´éœ²ç«¯å£\n",
    "EXPOSE 8000\n",
    "\n",
    "# å•Ÿå‹•å‘½ä»¤\n",
    "CMD [\"uvicorn\", \"main:app\", \"--host\", \"0.0.0.0\", \"--port\", \"8000\"]\n",
    "'''\n",
    "\n",
    "print(\"ğŸ“„ Dockerfile:\")\n",
    "print(dockerfile_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 docker-compose.yml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docker_compose_content = '''\n",
    "version: '3.8'\n",
    "\n",
    "services:\n",
    "  # FastAPI æ‡‰ç”¨\n",
    "  api:\n",
    "    build: .\n",
    "    container_name: cathay-ai-api\n",
    "    ports:\n",
    "      - \"8000:8000\"\n",
    "    environment:\n",
    "      - OPENAI_API_KEY=${OPENAI_API_KEY}\n",
    "      - DATABASE_URL=postgresql://user:pass@db:5432/cathay\n",
    "      - REDIS_URL=redis://cache:6379\n",
    "    depends_on:\n",
    "      - db\n",
    "      - cache\n",
    "    restart: unless-stopped\n",
    "    volumes:\n",
    "      - ./logs:/app/logs\n",
    "  \n",
    "  # PostgreSQL è³‡æ–™åº«\n",
    "  db:\n",
    "    image: postgres:15\n",
    "    container_name: cathay-db\n",
    "    environment:\n",
    "      - POSTGRES_USER=user\n",
    "      - POSTGRES_PASSWORD=pass\n",
    "      - POSTGRES_DB=cathay\n",
    "    ports:\n",
    "      - \"5432:5432\"\n",
    "    volumes:\n",
    "      - postgres_data:/var/lib/postgresql/data\n",
    "  \n",
    "  # Redis å¿«å–\n",
    "  cache:\n",
    "    image: redis:7-alpine\n",
    "    container_name: cathay-cache\n",
    "    ports:\n",
    "      - \"6379:6379\"\n",
    "    volumes:\n",
    "      - redis_data:/data\n",
    "\n",
    "volumes:\n",
    "  postgres_data:\n",
    "  redis_data:\n",
    "'''\n",
    "\n",
    "print(\"ğŸ“„ docker-compose.yml:\")\n",
    "print(docker_compose_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "requirements_content = '''\n",
    "langchain==0.1.0\n",
    "langchain-openai==0.0.5\n",
    "fastapi==0.108.0\n",
    "uvicorn[standard]==0.25.0\n",
    "pydantic==2.5.0\n",
    "python-dotenv==1.0.0\n",
    "redis==5.0.1\n",
    "psycopg2-binary==2.9.9\n",
    "sqlalchemy==2.0.23\n",
    "'''\n",
    "\n",
    "print(\"ğŸ“„ requirements.txt:\")\n",
    "print(requirements_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 5: ç”Ÿç”¢ç’°å¢ƒæœ€ä½³å¯¦è¸\n",
    "\n",
    "### 5.1 ç’°å¢ƒè®Šæ•¸ç®¡ç†"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic_settings import BaseSettings\n",
    "\n",
    "class Settings(BaseSettings):\n",
    "    \"\"\"æ‡‰ç”¨ç¨‹å¼è¨­å®š\"\"\"\n",
    "    \n",
    "    # API è¨­å®š\n",
    "    app_name: str = \"Cathay AI Customer Service\"\n",
    "    app_version: str = \"1.0.0\"\n",
    "    debug: bool = False\n",
    "    \n",
    "    # OpenAI\n",
    "    openai_api_key: str\n",
    "    openai_model: str = \"gpt-4\"\n",
    "    \n",
    "    # è³‡æ–™åº«\n",
    "    database_url: str = \"postgresql://user:pass@localhost/cathay\"\n",
    "    \n",
    "    # Redis\n",
    "    redis_url: str = \"redis://localhost:6379\"\n",
    "    \n",
    "    # CORS\n",
    "    cors_origins: list = [\"http://localhost:3000\"]\n",
    "    \n",
    "    class Config:\n",
    "        env_file = \".env\"\n",
    "\n",
    "# è¼‰å…¥è¨­å®š\n",
    "settings = Settings()\n",
    "\n",
    "print(\"âœ… è¨­å®šè¼‰å…¥å®Œæˆ\")\n",
    "print(f\"æ‡‰ç”¨åç¨±: {settings.app_name}\")\n",
    "print(f\"ç‰ˆæœ¬: {settings.app_version}\")\n",
    "print(f\"é™¤éŒ¯æ¨¡å¼: {settings.debug}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 éŒ¯èª¤è™•ç†èˆ‡æ—¥èªŒ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from datetime import datetime\n",
    "\n",
    "# è¨­å®šæ—¥èªŒ\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',\n",
    "    handlers=[\n",
    "        logging.FileHandler(f'logs/app_{datetime.now().strftime(\"%Y%m%d\")}.log'),\n",
    "        logging.StreamHandler()\n",
    "    ]\n",
    ")\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# å…¨åŸŸç•°å¸¸è™•ç†å™¨\n",
    "from fastapi import Request\n",
    "from fastapi.responses import JSONResponse\n",
    "\n",
    "@app.exception_handler(Exception)\n",
    "async def global_exception_handler(request: Request, exc: Exception):\n",
    "    \"\"\"å…¨åŸŸç•°å¸¸è™•ç†\"\"\"\n",
    "    logger.error(f\"Unhandled exception: {exc}\", exc_info=True)\n",
    "    \n",
    "    return JSONResponse(\n",
    "        status_code=500,\n",
    "        content={\n",
    "            \"error\": \"Internal Server Error\",\n",
    "            \"message\": str(exc) if settings.debug else \"An error occurred\"\n",
    "        }\n",
    "    )\n",
    "\n",
    "print(\"âœ… æ—¥èªŒèˆ‡éŒ¯èª¤è™•ç†è¨­å®šå®Œæˆ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 æ•ˆèƒ½ç›£æ§"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastapi import Request\n",
    "import time\n",
    "\n",
    "@app.middleware(\"http\")\n",
    "async def add_process_time_header(request: Request, call_next):\n",
    "    \"\"\"è¨˜éŒ„è«‹æ±‚è™•ç†æ™‚é–“\"\"\"\n",
    "    start_time = time.time()\n",
    "    \n",
    "    response = await call_next(request)\n",
    "    \n",
    "    process_time = time.time() - start_time\n",
    "    response.headers[\"X-Process-Time\"] = str(process_time)\n",
    "    \n",
    "    # è¨˜éŒ„æ…¢è«‹æ±‚\n",
    "    if process_time > 1.0:\n",
    "        logger.warning(f\"Slow request: {request.url.path} took {process_time:.2f}s\")\n",
    "    \n",
    "    return response\n",
    "\n",
    "print(\"âœ… æ•ˆèƒ½ç›£æ§ä¸­ä»‹å±¤è¨­å®šå®Œæˆ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.4 API æ–‡ä»¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FastAPI è‡ªå‹•ç”Ÿæˆ API æ–‡ä»¶\n",
    "print(\"ğŸ“š API æ–‡ä»¶:\")\n",
    "print(\"\\nSwagger UI: http://localhost:8000/docs\")\n",
    "print(\"ReDoc: http://localhost:8000/redoc\")\n",
    "print(\"OpenAPI Schema: http://localhost:8000/openapi.json\")\n",
    "\n",
    "# è‡ªè¨‚ API æ–‡ä»¶æ¨™ç±¤\n",
    "tags_metadata = [\n",
    "    {\n",
    "        \"name\": \"chat\",\n",
    "        \"description\": \"èŠå¤©ç›¸é—œ API\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"policy\",\n",
    "        \"description\": \"ä¿å–®æŸ¥è©¢ API\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"agent\",\n",
    "        \"description\": \"AI Agent API\"\n",
    "    }\n",
    "]\n",
    "\n",
    "# æ›´æ–°æ‡‰ç”¨ç¨‹å¼è¨­å®š\n",
    "app = FastAPI(\n",
    "    title=\"åœ‹æ³°äººå£½ AI å®¢æœ API\",\n",
    "    description=\"LangChain é©…å‹•çš„æ™ºèƒ½å®¢æœç³»çµ±\",\n",
    "    version=\"1.0.0\",\n",
    "    openapi_tags=tags_metadata\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 6: å®Œæ•´éƒ¨ç½²æµç¨‹\n",
    "\n",
    "### 6.1 æœ¬åœ°é–‹ç™¼"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deployment_steps = '''\n",
    "# 1. æœ¬åœ°é–‹ç™¼æµç¨‹\n",
    "\n",
    "## åˆå§‹åŒ–å°ˆæ¡ˆ\n",
    "mkdir cathay-ai-service\n",
    "cd cathay-ai-service\n",
    "python -m venv venv\n",
    "source venv/bin/activate  # Windows: venv\\\\Scripts\\\\activate\n",
    "\n",
    "## å®‰è£ä¾è³´\n",
    "pip install -r requirements.txt\n",
    "\n",
    "## è¨­å®šç’°å¢ƒè®Šæ•¸\n",
    "cp .env.example .env\n",
    "# ç·¨è¼¯ .env å¡«å…¥ API Keys\n",
    "\n",
    "## å•Ÿå‹•é–‹ç™¼ä¼ºæœå™¨\n",
    "uvicorn main:app --reload --port 8000\n",
    "\n",
    "# 2. æ¸¬è©¦\n",
    "\n",
    "## å¥åº·æª¢æŸ¥\n",
    "curl http://localhost:8000/\n",
    "\n",
    "## æ¸¬è©¦èŠå¤© API\n",
    "curl -X POST http://localhost:8000/chat \\\\\n",
    "  -H \"Content-Type: application/json\" \\\\\n",
    "  -d '{\"user_id\": \"test\", \"message\": \"ä½ å¥½\"}'\n",
    "\n",
    "# 3. Docker éƒ¨ç½²\n",
    "\n",
    "## å»ºç½®æ˜ åƒ\n",
    "docker build -t cathay-ai-service .\n",
    "\n",
    "## å•Ÿå‹•å®¹å™¨\n",
    "docker-compose up -d\n",
    "\n",
    "## æŸ¥çœ‹æ—¥èªŒ\n",
    "docker-compose logs -f api\n",
    "\n",
    "## åœæ­¢æœå‹™\n",
    "docker-compose down\n",
    "\n",
    "# 4. ç”Ÿç”¢éƒ¨ç½²\n",
    "\n",
    "## æ¨é€åˆ° Docker Registry\n",
    "docker tag cathay-ai-service registry.example.com/cathay-ai-service:1.0.0\n",
    "docker push registry.example.com/cathay-ai-service:1.0.0\n",
    "\n",
    "## Kubernetes éƒ¨ç½²\n",
    "kubectl apply -f k8s/deployment.yaml\n",
    "kubectl apply -f k8s/service.yaml\n",
    "kubectl apply -f k8s/ingress.yaml\n",
    "'''\n",
    "\n",
    "print(deployment_steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ¯ ç·´ç¿’é¡Œ\n",
    "\n",
    "### ç·´ç¿’ 1: å¯¦ä½œ API é€Ÿç‡é™åˆ¶\n",
    "\n",
    "æ¯å€‹ IP æ¯åˆ†é˜æœ€å¤š 60 æ¬¡è«‹æ±‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: å¯¦ä½œ RateLimiter middleware"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ç·´ç¿’ 2: å¯¦ä½œå¥åº·æª¢æŸ¥ç«¯é»\n",
    "\n",
    "æª¢æŸ¥è³‡æ–™åº«ã€Redisã€OpenAI é€£ç·šç‹€æ…‹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: å¯¦ä½œ /health ç«¯é»"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ç·´ç¿’ 3: å¯¦ä½œ Metrics æ”¶é›†\n",
    "\n",
    "æ”¶é›†è«‹æ±‚æ•¸ã€å›æ‡‰æ™‚é–“ã€éŒ¯èª¤ç‡ç­‰æŒ‡æ¨™"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: å¯¦ä½œ Prometheus metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“ å­¸ç¿’æª¢æŸ¥æ¸…å–®\n",
    "\n",
    "- [ ] ç†è§£ LangChain æ‡‰ç”¨çš„éƒ¨ç½²æ¶æ§‹\n",
    "- [ ] ä½¿ç”¨ FastAPI å»ºç«‹ REST API\n",
    "- [ ] å¯¦ä½œåŒæ­¥å’ŒéåŒæ­¥ç«¯é»\n",
    "- [ ] å¯¦ä½œä¸²æµå›æ‡‰ (SSE)\n",
    "- [ ] å»ºç«‹ Dockerfile å’Œ docker-compose.yml\n",
    "- [ ] è¨­å®šç’°å¢ƒè®Šæ•¸å’Œé…ç½®\n",
    "- [ ] å¯¦ä½œéŒ¯èª¤è™•ç†å’Œæ—¥èªŒ\n",
    "- [ ] å¯¦ä½œæ•ˆèƒ½ç›£æ§\n",
    "- [ ] ç”Ÿæˆ API æ–‡ä»¶\n",
    "- [ ] ç†è§£å®Œæ•´éƒ¨ç½²æµç¨‹\n",
    "\n",
    "## ğŸ“ èª²ç¨‹ç¸½çµ\n",
    "\n",
    "æ­å–œå®Œæˆ LangChain ç·´ç¿’ç³»åˆ—! ğŸ‰\n",
    "\n",
    "### ä½ å·²ç¶“å­¸æœƒ:\n",
    "\n",
    "1. **LangChain åŸºç¤** (01)\n",
    "   - PromptTemplate\n",
    "   - Chains\n",
    "   - Output Parsers\n",
    "\n",
    "2. **LangChain Agents** (02)\n",
    "   - ReAct æ¨¡å¼\n",
    "   - Tools å®šç¾©\n",
    "   - Agent Executor\n",
    "\n",
    "3. **çµæ§‹åŒ–è¼¸å‡º** (03)\n",
    "   - Pydantic Models\n",
    "   - with_structured_output()\n",
    "   - Tool/Provider Strategy\n",
    "\n",
    "4. **è¨˜æ†¶ç®¡ç†** (04)\n",
    "   - ConversationBufferMemory\n",
    "   - è‡ªè¨‚ State Schema\n",
    "   - Middleware è¨˜æ†¶å¢å¼·\n",
    "\n",
    "5. **é€²éš Middleware** (05)\n",
    "   - @before_model\n",
    "   - @after_model\n",
    "   - æ—¥èªŒã€å¿«å–ã€é‡è©¦\n",
    "\n",
    "6. **éƒ¨ç½²å¯¦å‹™** (06)\n",
    "   - FastAPI REST API\n",
    "   - ä¸²æµå›æ‡‰\n",
    "   - Docker å®¹å™¨åŒ–\n",
    "\n",
    "### ä¸‹ä¸€æ­¥å»ºè­°:\n",
    "\n",
    "- ğŸš€ å»ºç«‹è‡ªå·±çš„ LangChain å°ˆæ¡ˆ\n",
    "- ğŸ“š æ·±å…¥ç ”ç©¶ LangSmith ç›£æ§\n",
    "- ğŸ”§ æ¢ç´¢æ›´å¤š LangChain å·¥å…·å’Œæ•´åˆ\n",
    "- ğŸŒ è²¢ç»åˆ° LangChain ç¤¾ç¾¤\n",
    "\n",
    "### è³‡æº:\n",
    "\n",
    "- [LangChain å®˜æ–¹æ–‡ä»¶](https://python.langchain.com/)\n",
    "- [LangChain GitHub](https://github.com/langchain-ai/langchain)\n",
    "- [LangSmith](https://smith.langchain.com/)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
