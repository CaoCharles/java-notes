{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 04 - è¨˜æ†¶ç®¡ç† (Memory Management)\n",
    "\n",
    "## ğŸ“š å­¸ç¿’ç›®æ¨™\n",
    "\n",
    "- âœ… ç†è§£ LangChain çš„è¨˜æ†¶æ©Ÿåˆ¶\n",
    "- âœ… æŒæ¡çŸ­æœŸè¨˜æ†¶ (ConversationBufferMemory)\n",
    "- âœ… å­¸ç¿’è‡ªè¨‚ State Schema ç®¡ç†å°è©±ç‹€æ…‹\n",
    "- âœ… å¯¦ä½œå¸¶è¨˜æ†¶çš„å®¢æœ Agent\n",
    "- âœ… ä½¿ç”¨ Middleware å¢å¼·è¨˜æ†¶åŠŸèƒ½\n",
    "\n",
    "## â° é è¨ˆæ™‚é–“: 45 åˆ†é˜"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“¦ ç’°å¢ƒè¨­å®š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install langchain==0.1.0\n",
    "!pip install langchain-openai==0.0.5\n",
    "!pip install langgraph==0.0.20\n",
    "!pip install python-dotenv==1.0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "print(\"âœ… ç’°å¢ƒè¨­å®šå®Œæˆ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: ç‚ºä»€éº¼éœ€è¦è¨˜æ†¶?\n",
    "\n",
    "### 1.1 ç„¡è¨˜æ†¶çš„ Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4\", temperature=0)\n",
    "\n",
    "# ç¬¬ä¸€æ¬¡å°è©±\n",
    "response1 = llm.invoke(\"æˆ‘çš„ä¿å–®è™Ÿç¢¼æ˜¯ CL202401001\")\n",
    "print(\"ğŸ‘¤ ä½¿ç”¨è€…: æˆ‘çš„ä¿å–®è™Ÿç¢¼æ˜¯ CL202401001\")\n",
    "print(f\"ğŸ¤– AI: {response1.content}\\n\")\n",
    "\n",
    "# ç¬¬äºŒæ¬¡å°è©±\n",
    "response2 = llm.invoke(\"è«‹æŸ¥è©¢æˆ‘çš„ä¿å–®è³‡è¨Š\")\n",
    "print(\"ğŸ‘¤ ä½¿ç”¨è€…: è«‹æŸ¥è©¢æˆ‘çš„ä¿å–®è³‡è¨Š\")\n",
    "print(f\"ğŸ¤– AI: {response2.content}\")\n",
    "print(\"\\nâŒ å•é¡Œ: AI ä¸è¨˜å¾—ä¹‹å‰èªªéçš„ä¿å–®è™Ÿç¢¼!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 æ‰‹å‹•ç®¡ç†å°è©±æ­·å²"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema import HumanMessage, AIMessage, SystemMessage\n",
    "\n",
    "# æ‰‹å‹•ç¶­è­·å°è©±æ­·å²\n",
    "messages = [\n",
    "    SystemMessage(content=\"ä½ æ˜¯åœ‹æ³°äººå£½çš„å®¢æœåŠ©ç†\"),\n",
    "    HumanMessage(content=\"æˆ‘çš„ä¿å–®è™Ÿç¢¼æ˜¯ CL202401001\"),\n",
    "]\n",
    "\n",
    "response1 = llm.invoke(messages)\n",
    "messages.append(AIMessage(content=response1.content))\n",
    "print(f\"ğŸ¤– AI: {response1.content}\\n\")\n",
    "\n",
    "# ç¬¬äºŒæ¬¡å°è©± - è¨˜å¾—ä¹‹å‰çš„å…§å®¹\n",
    "messages.append(HumanMessage(content=\"è«‹æŸ¥è©¢æˆ‘çš„ä¿å–®è³‡è¨Š\"))\n",
    "response2 = llm.invoke(messages)\n",
    "print(f\"ğŸ¤– AI: {response2.content}\")\n",
    "print(\"\\nâœ… AI è¨˜å¾—ä¿å–®è™Ÿç¢¼äº†!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: ConversationBufferMemory\n",
    "\n",
    "### 2.1 åŸºç¤ç”¨æ³•"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.chains import ConversationChain\n",
    "\n",
    "# å»ºç«‹è¨˜æ†¶\n",
    "memory = ConversationBufferMemory()\n",
    "\n",
    "# å»ºç«‹å°è©±éˆ\n",
    "conversation = ConversationChain(\n",
    "    llm=llm,\n",
    "    memory=memory,\n",
    "    verbose=True  # é¡¯ç¤ºåŸ·è¡Œéç¨‹\n",
    ")\n",
    "\n",
    "# ç¬¬ä¸€è¼ªå°è©±\n",
    "response1 = conversation.predict(input=\"æˆ‘å«ç‹å°æ˜,æˆ‘çš„ä¿å–®è™Ÿç¢¼æ˜¯ CL202401001\")\n",
    "print(f\"\\nå›æ‡‰: {response1}\")\n",
    "\n",
    "# ç¬¬äºŒè¼ªå°è©±\n",
    "response2 = conversation.predict(input=\"è«‹å•æˆ‘å‰›æ‰èªªçš„ä¿å–®è™Ÿç¢¼æ˜¯ä»€éº¼?\")\n",
    "print(f\"\\nå›æ‡‰: {response2}\")\n",
    "\n",
    "# ç¬¬ä¸‰è¼ªå°è©±\n",
    "response3 = conversation.predict(input=\"æˆ‘å«ä»€éº¼åå­—?\")\n",
    "print(f\"\\nå›æ‡‰: {response3}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 æŸ¥çœ‹è¨˜æ†¶å…§å®¹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# æŸ¥çœ‹å®Œæ•´å°è©±æ­·å²\n",
    "print(\"ğŸ’¾ å°è©±æ­·å²:\")\n",
    "print(memory.buffer)\n",
    "\n",
    "# æŸ¥çœ‹çµæ§‹åŒ–çš„è¨Šæ¯åˆ—è¡¨\n",
    "print(\"\\nğŸ“‹ è¨Šæ¯åˆ—è¡¨:\")\n",
    "messages = memory.chat_memory.messages\n",
    "for i, msg in enumerate(messages, 1):\n",
    "    role = \"ğŸ‘¤\" if msg.type == \"human\" else \"ğŸ¤–\"\n",
    "    print(f\"{i}. {role} {msg.content}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 æ¸…é™¤è¨˜æ†¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# æ¸…é™¤è¨˜æ†¶\n",
    "memory.clear()\n",
    "print(\"ğŸ—‘ï¸ è¨˜æ†¶å·²æ¸…é™¤\")\n",
    "\n",
    "# æ¸¬è©¦\n",
    "response = conversation.predict(input=\"æˆ‘å«ä»€éº¼åå­—?\")\n",
    "print(f\"\\nå›æ‡‰: {response}\")\n",
    "print(\"\\nğŸ‘† AI å·²ç¶“ä¸è¨˜å¾—ä¹‹å‰çš„å°è©±äº†\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: è‡ªè¨‚ State Schema\n",
    "\n",
    "### 3.1 ä½¿ç”¨ TypedDict å®šç¾©ç‹€æ…‹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import TypedDict, Annotated, List\n",
    "from operator import add\n",
    "from langgraph.graph import StateGraph, END\n",
    "\n",
    "class ConversationState(TypedDict):\n",
    "    \"\"\"å°è©±ç‹€æ…‹\"\"\"\n",
    "    # å°è©±æ­·å² (ç´¯åŠ )\n",
    "    messages: Annotated[List[dict], add]\n",
    "    \n",
    "    # ä½¿ç”¨è€…è³‡è¨Š (è¦†è“‹)\n",
    "    user_name: str\n",
    "    policy_id: str\n",
    "    \n",
    "    # ç•¶å‰æ„åœ– (è¦†è“‹)\n",
    "    current_intent: str\n",
    "    \n",
    "    # åŸ·è¡Œæ—¥èªŒ (ç´¯åŠ )\n",
    "    execution_log: Annotated[List[str], add]\n",
    "\n",
    "print(\"âœ… è‡ªè¨‚ç‹€æ…‹çµæ§‹å®šç¾©å®Œæˆ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 å»ºç«‹å¸¶ç‹€æ…‹çš„ Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "def extract_info(state: ConversationState) -> ConversationState:\n",
    "    \"\"\"æ“·å–ä½¿ç”¨è€…è³‡è¨Š\"\"\"\n",
    "    last_msg = state[\"messages\"][-1][\"content\"] if state[\"messages\"] else \"\"\n",
    "    \n",
    "    # ç°¡å–®çš„è³‡è¨Šæ“·å– (å¯¦éš›æœƒç”¨ LLM)\n",
    "    user_name = state.get(\"user_name\", \"\")\n",
    "    policy_id = state.get(\"policy_id\", \"\")\n",
    "    \n",
    "    if \"æˆ‘å«\" in last_msg or \"æˆ‘æ˜¯\" in last_msg:\n",
    "        # æå–å§“å\n",
    "        for word in [\"æˆ‘å«\", \"æˆ‘æ˜¯\"]:\n",
    "            if word in last_msg:\n",
    "                user_name = last_msg.split(word)[1].split(\",\")[0].split(\"ã€‚\")[0].strip()\n",
    "                break\n",
    "    \n",
    "    if \"ä¿å–®\" in last_msg and \"CL\" in last_msg:\n",
    "        # æå–ä¿å–®è™Ÿç¢¼\n",
    "        import re\n",
    "        match = re.search(r'CL\\d+', last_msg)\n",
    "        if match:\n",
    "            policy_id = match.group()\n",
    "    \n",
    "    return {\n",
    "        \"user_name\": user_name,\n",
    "        \"policy_id\": policy_id,\n",
    "        \"execution_log\": [f\"[{datetime.now().strftime('%H:%M:%S')}] æ“·å–è³‡è¨Šå®Œæˆ\"]\n",
    "    }\n",
    "\n",
    "def generate_response(state: ConversationState) -> ConversationState:\n",
    "    \"\"\"ç”Ÿæˆå›æ‡‰\"\"\"\n",
    "    last_msg = state[\"messages\"][-1][\"content\"]\n",
    "    user_name = state.get(\"user_name\", \"\")\n",
    "    policy_id = state.get(\"policy_id\", \"\")\n",
    "    \n",
    "    # å»ºç«‹æç¤ºè©\n",
    "    context = f\"\"\"\n",
    "å·²çŸ¥è³‡è¨Š:\n",
    "- ä½¿ç”¨è€…å§“å: {user_name if user_name else 'æœªçŸ¥'}\n",
    "- ä¿å–®è™Ÿç¢¼: {policy_id if policy_id else 'æœªçŸ¥'}\n",
    "\n",
    "ä½¿ç”¨è€…å•é¡Œ: {last_msg}\n",
    "\n",
    "è«‹æ ¹æ“šå·²çŸ¥è³‡è¨Šå›ç­”å•é¡Œã€‚å¦‚æœè³‡è¨Šä¸è¶³,è«‹å‹å–„åœ°è©¢å•ã€‚\n",
    "\"\"\"\n",
    "    \n",
    "    response = llm.invoke(context)\n",
    "    \n",
    "    return {\n",
    "        \"messages\": [{\"role\": \"assistant\", \"content\": response.content}],\n",
    "        \"execution_log\": [f\"[{datetime.now().strftime('%H:%M:%S')}] ç”Ÿæˆå›æ‡‰å®Œæˆ\"]\n",
    "    }\n",
    "\n",
    "# å»ºç«‹ StateGraph\n",
    "workflow = StateGraph(ConversationState)\n",
    "workflow.add_node(\"extract\", extract_info)\n",
    "workflow.add_node(\"respond\", generate_response)\n",
    "\n",
    "workflow.set_entry_point(\"extract\")\n",
    "workflow.add_edge(\"extract\", \"respond\")\n",
    "workflow.add_edge(\"respond\", END)\n",
    "\n",
    "stateful_agent = workflow.compile()\n",
    "\n",
    "print(\"âœ… å¸¶ç‹€æ…‹çš„ Agent å»ºç«‹å®Œæˆ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 æ¸¬è©¦ç‹€æ…‹ç®¡ç†"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# åˆå§‹åŒ–ç‹€æ…‹\n",
    "state = {\n",
    "    \"messages\": [{\"role\": \"user\", \"content\": \"æˆ‘å«ç‹å°æ˜,æˆ‘çš„ä¿å–®æ˜¯ CL202401001\"}],\n",
    "    \"user_name\": \"\",\n",
    "    \"policy_id\": \"\",\n",
    "    \"current_intent\": \"\",\n",
    "    \"execution_log\": []\n",
    "}\n",
    "\n",
    "# ç¬¬ä¸€è¼ªå°è©±\n",
    "result1 = stateful_agent.invoke(state)\n",
    "\n",
    "print(\"ğŸ’¬ ç¬¬ä¸€è¼ªå°è©±:\")\n",
    "print(f\"ğŸ‘¤ ä½¿ç”¨è€…: {result1['messages'][0]['content']}\")\n",
    "print(f\"ğŸ¤– AI: {result1['messages'][1]['content']}\")\n",
    "print(f\"\\nğŸ“Š ç‹€æ…‹:\")\n",
    "print(f\"  å§“å: {result1['user_name']}\")\n",
    "print(f\"  ä¿å–®: {result1['policy_id']}\")\n",
    "print(f\"\\nğŸ“ æ—¥èªŒ:\")\n",
    "for log in result1['execution_log']:\n",
    "    print(f\"  {log}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ç¬¬äºŒè¼ªå°è©± - ä½¿ç”¨ç¬¬ä¸€è¼ªçš„ç‹€æ…‹\n",
    "result1[\"messages\"].append({\"role\": \"user\", \"content\": \"è«‹å•æˆ‘çš„ä¿å–®è™Ÿç¢¼æ˜¯ä»€éº¼?\"})\n",
    "\n",
    "result2 = stateful_agent.invoke(result1)\n",
    "\n",
    "print(\"\\nğŸ’¬ ç¬¬äºŒè¼ªå°è©±:\")\n",
    "print(f\"ğŸ‘¤ ä½¿ç”¨è€…: {result2['messages'][-2]['content']}\")\n",
    "print(f\"ğŸ¤– AI: {result2['messages'][-1]['content']}\")\n",
    "print(f\"\\nâœ… AI è¨˜å¾—ä¹‹å‰èªªéçš„ä¿å–®è™Ÿç¢¼: {result2['policy_id']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: Middleware å¢å¼·è¨˜æ†¶\n",
    "\n",
    "### 4.1 å»ºç«‹è¨˜æ†¶ä¸­ä»‹å±¤"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MemoryMiddleware:\n",
    "    \"\"\"è¨˜æ†¶ä¸­ä»‹å±¤\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.user_data = {}  # ä½¿ç”¨è€…è³‡æ–™å¿«å–\n",
    "        self.conversation_count = {}  # å°è©±è¨ˆæ•¸\n",
    "    \n",
    "    def before_invoke(self, state: ConversationState) -> ConversationState:\n",
    "        \"\"\"åŸ·è¡Œå‰è™•ç†\"\"\"\n",
    "        user_name = state.get(\"user_name\", \"\")\n",
    "        \n",
    "        if user_name:\n",
    "            # å¾å¿«å–è¼‰å…¥ä½¿ç”¨è€…è³‡æ–™\n",
    "            if user_name in self.user_data:\n",
    "                print(f\"ğŸ“‚ å¾å¿«å–è¼‰å…¥ {user_name} çš„è³‡æ–™\")\n",
    "                state.update(self.user_data[user_name])\n",
    "            \n",
    "            # æ›´æ–°å°è©±è¨ˆæ•¸\n",
    "            self.conversation_count[user_name] = self.conversation_count.get(user_name, 0) + 1\n",
    "        \n",
    "        return state\n",
    "    \n",
    "    def after_invoke(self, state: ConversationState) -> ConversationState:\n",
    "        \"\"\"åŸ·è¡Œå¾Œè™•ç†\"\"\"\n",
    "        user_name = state.get(\"user_name\", \"\")\n",
    "        \n",
    "        if user_name:\n",
    "            # å„²å­˜ä½¿ç”¨è€…è³‡æ–™åˆ°å¿«å–\n",
    "            self.user_data[user_name] = {\n",
    "                \"user_name\": user_name,\n",
    "                \"policy_id\": state.get(\"policy_id\", \"\"),\n",
    "                \"conversation_count\": self.conversation_count.get(user_name, 0)\n",
    "            }\n",
    "            print(f\"ğŸ’¾ å„²å­˜ {user_name} çš„è³‡æ–™åˆ°å¿«å–\")\n",
    "        \n",
    "        return state\n",
    "    \n",
    "    def get_user_stats(self, user_name: str) -> dict:\n",
    "        \"\"\"å–å¾—ä½¿ç”¨è€…çµ±è¨ˆ\"\"\"\n",
    "        return self.user_data.get(user_name, {})\n",
    "\n",
    "# å»ºç«‹ä¸­ä»‹å±¤å¯¦ä¾‹\n",
    "memory_middleware = MemoryMiddleware()\n",
    "\n",
    "print(\"âœ… è¨˜æ†¶ä¸­ä»‹å±¤å»ºç«‹å®Œæˆ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 æ¸¬è©¦ Middleware"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# æ¨¡æ“¬ç¬¬ä¸€æ¬¡å°è©±\n",
    "state1 = {\n",
    "    \"messages\": [{\"role\": \"user\", \"content\": \"æˆ‘å«æå°è¯,ä¿å–® CL202401002\"}],\n",
    "    \"user_name\": \"æå°è¯\",\n",
    "    \"policy_id\": \"CL202401002\",\n",
    "    \"current_intent\": \"\",\n",
    "    \"execution_log\": []\n",
    "}\n",
    "\n",
    "print(\"ğŸ”„ ç¬¬ä¸€æ¬¡å°è©±:\")\n",
    "state1 = memory_middleware.before_invoke(state1)\n",
    "# ... åŸ·è¡Œ Agent ...\n",
    "state1 = memory_middleware.after_invoke(state1)\n",
    "\n",
    "# æ¨¡æ“¬ç¬¬äºŒæ¬¡å°è©± (æ–°æœƒè©±)\n",
    "state2 = {\n",
    "    \"messages\": [{\"role\": \"user\", \"content\": \"æˆ‘æƒ³æŸ¥è©¢ä¿å–®\"}],\n",
    "    \"user_name\": \"æå°è¯\",  # åŒä¸€å€‹ä½¿ç”¨è€…\n",
    "    \"policy_id\": \"\",  # æ²’æœ‰æä¾›ä¿å–®è™Ÿç¢¼\n",
    "    \"current_intent\": \"\",\n",
    "    \"execution_log\": []\n",
    "}\n",
    "\n",
    "print(\"\\nğŸ”„ ç¬¬äºŒæ¬¡å°è©± (åŒä¸€ä½¿ç”¨è€…):\")\n",
    "state2 = memory_middleware.before_invoke(state2)\n",
    "print(f\"\\nâœ… è‡ªå‹•å¡«å…¥ä¿å–®è™Ÿç¢¼: {state2['policy_id']}\")\n",
    "print(f\"âœ… å°è©±æ¬¡æ•¸: {memory_middleware.conversation_count['æå°è¯']}\")\n",
    "\n",
    "# æŸ¥çœ‹ä½¿ç”¨è€…çµ±è¨ˆ\n",
    "print(\"\\nğŸ“Š ä½¿ç”¨è€…çµ±è¨ˆ:\")\n",
    "stats = memory_middleware.get_user_stats(\"æå°è¯\")\n",
    "print(stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 5: å®Œæ•´å®¢æœç³»çµ±\n",
    "\n",
    "### 5.1 æ•´åˆæ‰€æœ‰åŠŸèƒ½"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomerServiceState(TypedDict):\n",
    "    \"\"\"å®¢æœç³»çµ±ç‹€æ…‹\"\"\"\n",
    "    session_id: str\n",
    "    messages: Annotated[List[dict], add]\n",
    "    user_name: str\n",
    "    policy_id: str\n",
    "    intent: str\n",
    "    sentiment: str  # positive/neutral/negative\n",
    "    resolved: bool\n",
    "    execution_log: Annotated[List[str], add]\n",
    "\n",
    "def analyze_message(state: CustomerServiceState) -> CustomerServiceState:\n",
    "    \"\"\"åˆ†æè¨Šæ¯æ„åœ–å’Œæƒ…æ„Ÿ\"\"\"\n",
    "    last_msg = state[\"messages\"][-1][\"content\"]\n",
    "    \n",
    "    # ä½¿ç”¨ LLM åˆ†æ\n",
    "    analysis_prompt = f\"\"\"\n",
    "åˆ†æä»¥ä¸‹å®¢æˆ¶è¨Šæ¯:\n",
    "{last_msg}\n",
    "\n",
    "è«‹åˆ¤æ–·:\n",
    "1. æ„åœ– (æŸ¥è©¢/æŠ•è¨´/è³¼è²·/å…¶ä»–)\n",
    "2. æƒ…æ„Ÿ (positive/neutral/negative)\n",
    "\n",
    "åªå›ç­” JSON: {{\"intent\": \"...\", \"sentiment\": \"...\"}}\n",
    "\"\"\"\n",
    "    \n",
    "    response = llm.invoke(analysis_prompt)\n",
    "    import json\n",
    "    try:\n",
    "        analysis = json.loads(response.content)\n",
    "    except:\n",
    "        analysis = {\"intent\": \"å…¶ä»–\", \"sentiment\": \"neutral\"}\n",
    "    \n",
    "    return {\n",
    "        \"intent\": analysis[\"intent\"],\n",
    "        \"sentiment\": analysis[\"sentiment\"],\n",
    "        \"execution_log\": [f\"[åˆ†æ] æ„åœ–: {analysis['intent']}, æƒ…æ„Ÿ: {analysis['sentiment']}\"]\n",
    "    }\n",
    "\n",
    "def handle_query(state: CustomerServiceState) -> CustomerServiceState:\n",
    "    \"\"\"è™•ç†å®¢æˆ¶æŸ¥è©¢\"\"\"\n",
    "    context = f\"\"\"\n",
    "å®¢æˆ¶è³‡è¨Š:\n",
    "- å§“å: {state.get('user_name', 'æœªçŸ¥')}\n",
    "- ä¿å–®: {state.get('policy_id', 'æœªçŸ¥')}\n",
    "- æ„åœ–: {state.get('intent', 'æœªçŸ¥')}\n",
    "- æƒ…æ„Ÿ: {state.get('sentiment', 'æœªçŸ¥')}\n",
    "\n",
    "å°è©±æ­·å²:\n",
    "\"\"\"\n",
    "    for msg in state[\"messages\"]:\n",
    "        role = \"å®¢æˆ¶\" if msg[\"role\"] == \"user\" else \"å®¢æœ\"\n",
    "        context += f\"{role}: {msg['content']}\\n\"\n",
    "    \n",
    "    context += \"\\nè«‹æ ¹æ“šä»¥ä¸Šè³‡è¨Š,æä¾›å°ˆæ¥­ä¸”å‹å–„çš„å›æ‡‰ã€‚\"\n",
    "    \n",
    "    response = llm.invoke(context)\n",
    "    \n",
    "    return {\n",
    "        \"messages\": [{\"role\": \"assistant\", \"content\": response.content}],\n",
    "        \"resolved\": True,  # ç°¡åŒ–è™•ç†\n",
    "        \"execution_log\": [f\"[å›æ‡‰] å·²ç”Ÿæˆå®¢æœå›æ‡‰\"]\n",
    "    }\n",
    "\n",
    "# å»ºç«‹å®Œæ•´å®¢æœ Agent\n",
    "cs_workflow = StateGraph(CustomerServiceState)\n",
    "cs_workflow.add_node(\"analyze\", analyze_message)\n",
    "cs_workflow.add_node(\"handle\", handle_query)\n",
    "\n",
    "cs_workflow.set_entry_point(\"analyze\")\n",
    "cs_workflow.add_edge(\"analyze\", \"handle\")\n",
    "cs_workflow.add_edge(\"handle\", END)\n",
    "\n",
    "customer_service = cs_workflow.compile()\n",
    "\n",
    "print(\"âœ… å®Œæ•´å®¢æœç³»çµ±å»ºç«‹å®Œæˆ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 æ¸¬è©¦å®¢æœç³»çµ±"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# å ´æ™¯ 1: æ­£å¸¸æŸ¥è©¢\n",
    "session1 = {\n",
    "    \"session_id\": \"S001\",\n",
    "    \"messages\": [{\"role\": \"user\", \"content\": \"ä½ å¥½,æˆ‘æƒ³æŸ¥è©¢æˆ‘çš„ä¿å–®è³‡è¨Š,ä¿å–®è™Ÿç¢¼æ˜¯ CL202401001\"}],\n",
    "    \"user_name\": \"ç‹å°æ˜\",\n",
    "    \"policy_id\": \"CL202401001\",\n",
    "    \"intent\": \"\",\n",
    "    \"sentiment\": \"\",\n",
    "    \"resolved\": False,\n",
    "    \"execution_log\": []\n",
    "}\n",
    "\n",
    "result = customer_service.invoke(session1)\n",
    "\n",
    "print(\"ğŸ“ å®¢æœå°è©±:\")\n",
    "print(\"=\"*60)\n",
    "print(f\"ğŸ‘¤ å®¢æˆ¶: {result['messages'][0]['content']}\")\n",
    "print(f\"\\nğŸ¤– å®¢æœ: {result['messages'][1]['content']}\")\n",
    "print(f\"\\nğŸ“Š åˆ†æçµæœ:\")\n",
    "print(f\"  æ„åœ–: {result['intent']}\")\n",
    "print(f\"  æƒ…æ„Ÿ: {result['sentiment']}\")\n",
    "print(f\"  å·²è§£æ±º: {result['resolved']}\")\n",
    "print(f\"\\nğŸ“ åŸ·è¡Œæ—¥èªŒ:\")\n",
    "for log in result['execution_log']:\n",
    "    print(f\"  {log}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ¯ ç·´ç¿’é¡Œ\n",
    "\n",
    "### ç·´ç¿’ 1: å¯¦ä½œå°è©±æ‘˜è¦åŠŸèƒ½\n",
    "\n",
    "ç•¶å°è©±è¶…é 10 è¼ªæ™‚,è‡ªå‹•ç”¢ç”Ÿæ‘˜è¦ä¸¦å£“ç¸®æ­·å²è¨˜éŒ„"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: å¯¦ä½œ ConversationSummaryMemory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ç·´ç¿’ 2: å¤šä½¿ç”¨è€…è¨˜æ†¶éš”é›¢\n",
    "\n",
    "å¯¦ä½œæŒ‰ user_id å€åˆ†ä¸åŒä½¿ç”¨è€…çš„è¨˜æ†¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: å¯¦ä½œ MultiUserMemory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“ å­¸ç¿’æª¢æŸ¥æ¸…å–®\n",
    "\n",
    "- [ ] ç†è§£ç‚ºä»€éº¼éœ€è¦è¨˜æ†¶ç®¡ç†\n",
    "- [ ] ä½¿ç”¨ ConversationBufferMemory\n",
    "- [ ] è‡ªè¨‚ State Schema ç®¡ç†è¤‡é›œç‹€æ…‹\n",
    "- [ ] ä½¿ç”¨ Annotated å¯¦ç¾ç´¯åŠ æ›´æ–°\n",
    "- [ ] å»ºç«‹ Middleware å¢å¼·è¨˜æ†¶åŠŸèƒ½\n",
    "- [ ] æ•´åˆè¨˜æ†¶åˆ°å®¢æœç³»çµ±\n",
    "- [ ] å¯¦ä½œå°è©±æ­·å²è¿½è¹¤\n",
    "- [ ] è™•ç†ä½¿ç”¨è€…è³‡è¨Šå¿«å–\n",
    "\n",
    "## ä¸‹ä¸€æ­¥\n",
    "ç¹¼çºŒå‰å¾€ `05-middleware-advanced.ipynb` å­¸ç¿’é€²éšä¸­ä»‹å±¤æŠ€è¡“ ğŸ‘‰"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
